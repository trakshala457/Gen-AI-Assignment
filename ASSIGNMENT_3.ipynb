{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOo2JdA6bFk/6gvhcJNSGmI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trakshala457/Gen-AI-Assignment/blob/main/ASSIGNMENT_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Hugging Face APIs to integrate LLMs"
      ],
      "metadata": {
        "id": "7v1z19DOuLSO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-POxK0TslV5G",
        "outputId": "acb83986-c3d1-497e-8e50-2e2b2d5e3d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "from getpass import getpass\n",
        "import textwrap\n",
        "\n",
        "try:\n",
        "  hf_token = getpass(\"Enter your token:::::\")\n",
        "  client = InferenceClient(model=\"mistralai/Mistral-7B-Instruct-v0.2\", token=hf_token)\n",
        "  question = input(\"Enter your question:::::\")\n",
        "\n",
        "  messages = [\n",
        "      {\"role\":\"system\", \"content\":\"You are a knowledgable, helpful teacher.\"},\n",
        "      {\"role\":\"user\", \"content\":question}\n",
        "  ]\n",
        "\n",
        "  response = client.chat_completion(messages=messages, max_tokens = 200, temperature=0.7)\n",
        "\n",
        "  print(textwrap.fill(response.choices[0].message.content.strip(), width=90))\n",
        "except Exception as e:\n",
        "  print(f\"Error:{e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEfCo7mRloSB",
        "outputId": "68d27da5-65c2-4a96-b5ca-8718f92f70a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your token:::::··········\n",
            "Enter your question:::::Explain the process of Photosynthesis.\n",
            "Photosynthesis is a vital process that plants use to convert carbon dioxide (CO2) and\n",
            "water (H2O) into glucose (a type of sugar) and oxygen (O2) through the interaction of\n",
            "sunlight, chlorophyll, and water. This process occurs primarily in the chloroplasts of\n",
            "plant cells, with the leaves being the primary site for photosynthesis.  There are two\n",
            "main stages in photosynthesis: the light-dependent reactions and the light-independent\n",
            "reactions (Calvin cycle).  1. Light-dependent reactions: This process takes place in the\n",
            "thylakoid membranes of the chloroplasts. When sunlight strikes the chlorophyll molecules,\n",
            "it is absorbed, and the energy is used to create ATP (adenosine triphosphate) through the\n",
            "process of photophosphorylation. Additionally, light energy is used to produce NAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM and Temperature Tunning"
      ],
      "metadata": {
        "id": "Ht1mqs6HvUWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p31pEsIevTzw",
        "outputId": "e9976822-aa12-4555-bb28-33721b599b08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "temperature=0.7"
      ],
      "metadata": {
        "id": "QPeGB40x2I0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import textwrap\n",
        "\n",
        "prompt = input(\"Enter the beginning:::::\")\n",
        "\n",
        "def generate(prompt, max_length=250, temperature=0.7):\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "  model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "  input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "  output = model.generate(input_ids,\n",
        "                          max_length=max_length,\n",
        "                          temperature=temperature,\n",
        "                          do_sample=True,\n",
        "                          top_k=50,\n",
        "                          top_p=0.5,\n",
        "                          repetition_penalty=1.2,\n",
        "                          pad_token_id=tokenizer.eos_token_id\n",
        "                          )\n",
        "  return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "print(textwrap.fill(generate(prompt), width=90))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHDciyGQwW-u",
        "outputId": "7aa64f27-6164-4517-a0ee-f6b676dde00c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the beginning:::::It all started when the sky turned purple for the first time...\n",
            "It all started when the sky turned purple for the first time... I was in a dark room with\n",
            "no light, and I saw two people sitting on chairs. One of them had an enormous red sword\n",
            "that looked like it could be used to cut through everything around him! The other one\n",
            "didn't have any weapons at his side so he just stood there looking down from above while\n",
            "staring straight ahead as if nothing happened… And then suddenly something came out right\n",
            "before my eyes: \"The Dragon King is here!\" A giant black dragon appeared behind me\n",
            "immediately after being summoned by this mysterious figure!! It seemed even more powerful\n",
            "than what we were seeing earlier but its size wasn´t much smaller compared towards us or\n",
            "anything else!!! What did you think? That guy who only wanted some food would come up\n",
            "against someone whose strength isn`T great!? But now they are actually able fight\n",
            "together?! In addition…… Well maybe because their power level has increased….. They can\n",
            "also use magic attacks which will cause huge damage over long distances…. If these guys\n",
            "really want those things (and perhaps others) why not let go of your friends?? We should\n",
            "try our best too since everyone's lives depend on eachother~ Anyway.. As expected i got\n",
            "excited about how big she\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "temperature=0.3"
      ],
      "metadata": {
        "id": "n1rWeNuU2MB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import textwrap\n",
        "\n",
        "prompt = input(\"Enter the beginning:::::\")\n",
        "\n",
        "def generate(prompt, max_length=250, temperature=0.3):\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "  model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "  input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "  output = model.generate(input_ids,\n",
        "                          max_length=max_length,\n",
        "                          temperature=temperature,\n",
        "                          do_sample=True,\n",
        "                          top_k=50,\n",
        "                          top_p=0.5,\n",
        "                          repetition_penalty=1.2,\n",
        "                          pad_token_id=tokenizer.eos_token_id\n",
        "                          )\n",
        "  return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(textwrap.fill(generate(prompt), width=90))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23h7eOOk2Ut7",
        "outputId": "7fb57778-c7ac-4649-f75b-f3ba8dbb61b0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the beginning:::::It all started when the sky turned purple for the first time...\n",
            "It all started when the sky turned purple for the first time... \"I'm sorry, I didn't mean\n",
            "to...\" The girl said. \"But you're not going anywhere.\" She looked at me with a sad\n",
            "expression on her face. \"...You don' think that's okay?\" she asked in an angry tone. \"What\n",
            "do you want from us? You know what we've done here before and now it seems like there are\n",
            "no other options left!\" Her voice was so loud as if someone had just been hit by\n",
            "lightning! It sounded very much out of place right next door but even though my heart felt\n",
            "bad about this situation (and maybe because they were both young), everyone else seemed\n",
            "happy too!! And then suddenly something happened!!! My body began shaking\n",
            "uncontrollably!!!! A huge explosion shook everything around them - including myself ! But\n",
            "after seeing how quickly things got crazy again , people stopped talking or doing anything\n",
            "except staring into each others eyes while their bodies became completely numb . Everyone\n",
            "knew who did which one would be injured most :-/ They couldn`t see anyone outside anymore\n",
            ";-) So instead of being able only watch helplessly through every single person looking up\n",
            "towards him ... Then he saw his sister standing over beside himself.. He could feel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "temperature=1.0"
      ],
      "metadata": {
        "id": "ZIU9J6NB2M_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import textwrap\n",
        "\n",
        "prompt = input(\"Enter the beginning:::::\")\n",
        "\n",
        "def generate(prompt, max_length=250, temperature=1.0):\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "  model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "  input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "  output = model.generate(input_ids,\n",
        "                          max_length=max_length,\n",
        "                          temperature=temperature,\n",
        "                          do_sample=True,\n",
        "                          top_k=50,\n",
        "                          top_p=0.5,\n",
        "                          repetition_penalty=1.2,\n",
        "                          pad_token_id=tokenizer.eos_token_id\n",
        "                          )\n",
        "  return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(textwrap.fill(generate(prompt), width=90))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4HHAkG72jBR",
        "outputId": "4e9c35ec-c41a-4b97-bd4d-511df4d5faa4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the beginning:::::It all started when the sky turned purple for the first time...\n",
            "It all started when the sky turned purple for the first time... The blue-haired girl\n",
            "looked at me with a sad expression. \"You're so cute, I don't know why you are smiling like\n",
            "that.\" She gave me an apologetic look and then she said: \"...I am not really sure how to\n",
            "explain it...\" In my heart of hearts was something called 'love'. It is love in which we\n",
            "share feelings between people who feel very close together but also have some kind or\n",
            "other connection (for example if they had been separated from each others). The reason\n",
            "this happens often has to do entirely on their own terms - there must be someone else\n",
            "around too! This person may think he/she can only see her friends because his face looks\n",
            "different than hers due both eyes coloration as well as being more humanized compared\n",
            "him(or herself) looking even younger by comparison; however no matter what happened after\n",
            "those moments during our friendship ended up becoming quite awkward again.... There were\n",
            "many reasons behind these two events happening before us either alone nor through another\n",
            "relationship.. For instance one might believe otherwise based solely upon personal\n",
            "experience while watching TV since none could truly understand anything about them apart\n",
            "FROM THE NATURE OF THEIR FRIENDS AND ACHIE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "temperature=1.3"
      ],
      "metadata": {
        "id": "hHlfsdz32NBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import textwrap\n",
        "\n",
        "prompt = input(\"Enter the beginning:::::\")\n",
        "\n",
        "def generate(prompt, max_length=250, temperature=1.3):\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "  model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "  input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "  output = model.generate(input_ids,\n",
        "                          max_length=max_length,\n",
        "                          temperature=temperature,\n",
        "                          do_sample=True,\n",
        "                          top_k=50,\n",
        "                          top_p=0.5,\n",
        "                          repetition_penalty=1.2,\n",
        "                          pad_token_id=tokenizer.eos_token_id\n",
        "                          )\n",
        "  return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(textwrap.fill(generate(prompt), width=90))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSL4QYTI2kCD",
        "outputId": "34e9e649-ee2b-440b-834d-a70674789dd1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the beginning:::::It all started when the sky turned purple for the first time...\n",
            "It all started when the sky turned purple for the first time... \"Huh? What?\" Yuuko asked,\n",
            "and then she felt a sudden chill run down her spine. \"I think it's been five years.\"\n",
            "(TN: She was referring to three months of constant sleepiness from last night.) This\n",
            "morning is going through this very strange experience as well! I have not had any dreams\n",
            "since waking up so long ago...\" It looked like something he would probably never see again\n",
            "if there wasn't another one in existence… He just thought that somehow some weird little\n",
            "ghost might be haunting his room tonight but even now no-one has ever seen him before or\n",
            "after.. Maybe they could hear them while watching TV together right next door…. Or maybe……\n",
            "oh my god why did these things happen?! Why were you doing such an insane act on me\n",
            "today!? And what about our new guest who made us laugh at each other over dinner with\n",
            "delicious sushi instead?? Oh shit how are we gonna end every day having fun too huh….. How\n",
            "do YOU know someone really likes your cooking!! The feeling came out slowly; everyone\n",
            "began laughing hysterically around their own table without knowing where exactly until\n",
            "later because nobody knew anything else besides themselves which caused more chaos than\n",
            "usual\n"
          ]
        }
      ]
    }
  ]
}